// sandbox.js - Model Loading for Chrome Extension
let model = null;
let modelLoading = false;
let modelLoadPromise = null;

// Get model URL from the extension context
function getModelUrl() {
    const currentUrl = document.location.href;
    const baseUrl = currentUrl.substring(0, currentUrl.lastIndexOf('/') + 1);
    return baseUrl + 'model.json';
}

const modelUrl = getModelUrl();
const baseDirectory = modelUrl.replace('model.json', '');
console.log(`üîó Detected extension base URL: ${baseDirectory}`);

// Custom IOHandler that implements the full TensorFlow.js io.IOHandler interface
class ExtensionIOHandler {
    async load() {
        console.log(`üì• Fetching model manifest...`);
        const response = await fetch(modelUrl);
        if (!response.ok) throw new Error(`Failed to fetch model.json: ${response.statusText}`);
        
        const modelArtifacts = await response.json();
        console.log(`‚úÖ Model topology loaded`);
        
        // Extract weightSpecs from weightsManifest
        const weightsManifest = modelArtifacts.weightsManifest || [];
        const weightSpecs = [];
        const groupOrder = [];
        
        for (let groupIdx = 0; groupIdx < weightsManifest.length; groupIdx++) {
            const manifestGroup = weightsManifest[groupIdx];
            groupOrder.push(manifestGroup.paths[0]); // Track path for ordering
            
            for (const weight of manifestGroup.weights) {
                weightSpecs.push({
                    name: weight.name,
                    shape: weight.shape,
                    dtype: weight.dtype
                });
            }
        }
        
        console.log(`üìã Extracted ${weightSpecs.length} weight specs from manifest`);
        
        // Now fetch and assemble all weights in manifest order
        console.log(`üìä Fetching weight shards...`);
        const weightArrays = [];
        
        for (let groupIdx = 0; groupIdx < weightsManifest.length; groupIdx++) {
            const manifestGroup = weightsManifest[groupIdx];
            for (const path of manifestGroup.paths) {
                const url = baseDirectory + path;
                console.log(`üì• Fetching: ${path}`);
                
                const fileResponse = await fetch(url);
                if (!fileResponse.ok) throw new Error(`Failed to fetch ${path}`);
                
                const buffer = await fileResponse.arrayBuffer();
                weightArrays.push(new Uint8Array(buffer));
            }
        }
        
        console.log(`‚úÖ All ${weightArrays.length} weight shards loaded`);
        
        // Concatenate all weights into a single buffer
        let totalBytes = 0;
        for (const shard of weightArrays) {
            totalBytes += shard.length;
        }
        
        const concatenatedWeights = new Uint8Array(totalBytes);
        let offset = 0;
        for (const shard of weightArrays) {
            concatenatedWeights.set(shard, offset);
            offset += shard.length;
        }
        
        console.log(`‚úÖ Concatenated weights: ${totalBytes} bytes`);
        console.log(`üì¶ Return structure: modelTopology=${Object.keys(modelArtifacts.modelTopology).length} keys, weightSpecs=${weightSpecs.length} items`);
        
        return {
            modelTopology: modelArtifacts.modelTopology,
            weightSpecs: weightSpecs,
            weightData: concatenatedWeights.buffer
        };
    }
    
    async save() {
        throw new Error('Saving model is not supported');
    }
}

// Register the IOHandler
tf.io.registerLoadRouter((url) => {
    if (typeof url === 'string' && url.includes('chrome-extension://')) {
        console.log(`‚úÖ Using ExtensionIOHandler for: ${url}`);
        return new ExtensionIOHandler();
    }
    return null;
});

async function loadModel() {
    if (model) return; // Already loaded
    if (modelLoading) return modelLoadPromise; // Currently loading
    
    modelLoading = true;
    modelLoadPromise = (async () => {
        try {
            console.log("üß† Loading AI model...");
            console.log(`üìç Model URL: ${modelUrl}`);
            
            model = await tf.loadGraphModel(modelUrl);
            
            console.log("‚úÖ [Sandbox] Brain Loaded!");
            console.log(`üß¨ Model ready - Inputs: ${model.inputs.length}, Outputs: ${model.outputs.length}`);
            window.parent.postMessage({ type: 'MODEL_LOADED' }, '*');
            return model;
        } catch (err) {
            console.error("‚ùå [Sandbox] Load Failed:", err.message);
            modelLoading = false;
            modelLoadPromise = null;
            throw err;
        }
    })();
    
    return modelLoadPromise;
}

// Handle messages from content.js
window.addEventListener('message', async (event) => {
    const { type, payload, id } = event.data;

    if (type === 'CLASSIFY') {
        try {
            // Wait for model if it's still loading
            const readyModel = model || await loadModel();
            if (!readyModel) {
                console.error("‚ùå Model failed to load");
                return;
            }
            
            // 1. Create an image element from the data sent
            const img = new Image();
            img.onload = async () => {
                try {
                    // 2. Predict
                    const tensor = tf.browser.fromPixels(img)
                        .resizeNearestNeighbor([224, 224])
                        .toFloat()
                        .expandDims();
                    
                    const predictions = await readyModel.predict(tensor).data();
                    tensor.dispose();

                    // 3. Find top class
                    let maxScore = -1;
                    let maxIndex = -1;
                    for (let i = 0; i < predictions.length; i++) {
                        if (predictions[i] > maxScore) {
                            maxScore = predictions[i];
                            maxIndex = i;
                        }
                    }

                    // 4. Send Verdict back to Page
                    window.parent.postMessage({ 
                        type: 'VERDICT', 
                        id: id, 
                        index: maxIndex,
                        score: maxScore
                    }, '*');

                } catch (e) {
                    console.error("‚ùå Prediction error:", e.message);
                }
            };
            img.onerror = () => console.error("‚ùå Failed to load image data");
            img.src = payload; // Load the image data
        } catch (err) {
            console.error("‚ùå CLASSIFY handler error:", err.message);
        }
    }
});

// Start loading the model when the script loads
loadModel();
